import os
import logging
from urllib.parse import urlparse, parse_qs
from flask import Flask, render_template, request, jsonify, Response, send_file
from werkzeug.middleware.proxy_fix import ProxyFix
from scraper import process_all_cids_sequential, start_progress_ticker
from flask import Flask
from scraper import print_file

logging.basicConfig(level=logging.INFO)

# ê¸°ì¤€ ê°€ê²©ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ì „ì—­ ë³€ìˆ˜
global_base_price = None
global_base_price_cid_name = ''
global_page_title = ''
is_cancelled = False  # ë¶„ì„ ì¤‘ë‹¨ í”Œë˜ê·¸

# create the app
app = Flask(__name__)
app.secret_key = os.environ.get("SESSION_SECRET", "default_secret_key_for_development")
app.wsgi_app = ProxyFix(app.wsgi_app, x_proto=1, x_host=1)

logging.getLogger("werkzeug").setLevel(logging.WARNING)  # INFO ë¡œê·¸ ìˆ¨ê¹€

def _start_ticker_once():
    # ê°œë°œ ì„œë²„(reloader) ì¤‘ë³µ ì‹¤í–‰ íšŒí”¼ëŠ” í•„ìš” ì‹œ ì¶”ê°€
    start_progress_ticker(logger=app.logger)

@app.route('/')
def index():
    """Main page with URL input form"""
    return render_template('index.html')

@app.route('/scrape', methods=['POST'])
def scrape():
    """Handle single CID scraping request"""
    try:
        # ì¤‘ë‹¨ í”Œë˜ê·¸ í™•ì¸
        global is_cancelled

        app.logger.info(f"is_cancelled: {is_cancelled}")

        data = request.get_json()
        url = data.get('url', '').strip()
        step = data.get('step', 0)

        # ìƒˆ ì‹œì‘ì€ ì–¸ì œë‚˜ ì·¨ì†Œ í”Œë˜ê·¸ ë¬´ì‹œí•˜ê³  ì´ˆê¸°í™”
        if step == 0:
            is_cancelled = False
            app.logger.info("ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘ - ì¤‘ë‹¨ í”Œë˜ê·¸ ì´ˆê¸°í™”")
        else:
            # ì§„í–‰ ì¤‘ ë‹¨ê³„ì—ì„œë§Œ ì·¨ì†Œ ë°˜ì˜
            if is_cancelled:
                is_cancelled = False
                return jsonify({'status': 'cancelled', 'message': 'ë¶„ì„ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.'}), 200

        if not url:
            return jsonify({'error': 'URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”'}), 400

        # Add protocol if missing
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url

        # [ê²€ìƒ‰ì°½ë¦¬ìŠ¤íŠ¸] CID ê°’ë“¤
        search_cids = [
            ('-1', 'ì‹œí¬ë¦¿ì°½'),
            ('1829968', 'êµ¬ê¸€ì§€ë„A'),
            ('1917614', 'êµ¬ê¸€ì§€ë„B'),
            ('1833981', 'êµ¬ê¸€ì§€ë„C'),
            ('1776688', 'êµ¬ê¸€ ê²€ìƒ‰A'),
            ('1922868', 'êµ¬ê¸€ ê²€ìƒ‰B'),
            ('1908612', 'êµ¬ê¸€ ê²€ìƒ‰C'),
            ('1807747', 'VIO'),
            ('1838029', 'í˜¸í…”ìŠ¤ì»´ë°”ì¸'),
            ('1928503', 'BluePillow'),
            ('1729890', 'ë„¤ì´ë²„'),
            ('1587497', 'TripAdvisor')
        ]

        # [ì¹´ë“œë¦¬ìŠ¤íŠ¸] CID ê°’ë“¤
        card_cids = [
            ('1942636', 'ì¹´ì¹´ì˜¤í˜ì´'),
            ('1895693', 'í˜„ëŒ€ì¹´ë“œ'),
            ('1563295', 'êµ­ë¯¼ì¹´ë“œ'),
            ('1654104', 'ìš°ë¦¬ì¹´ë“œ'),
            ('1748498', 'BCì¹´ë“œ'),
            ('1760133', 'ì‹ í•œì¹´ë“œ'),
            ('1729471', 'í•˜ë‚˜ì¹´ë“œ'),
            ('1917334', 'í† ìŠ¤'),
            ('1783115', 'ì‚¼ì„±ì¹´ë“œ'),
            ('1827579', 'ë†í˜‘ì¹´ë“œ'),
            ('1917349', 'íŠ¸ë ˆë¸”ì›”ë ›'),
            ('1845157', 'í˜ì´ì½”'),
            ('1889319', 'ë¹„ì'),
            ('1889572', 'ë§ˆìŠ¤í„°ì¹´ë“œ'),
            ('1801110', 'ìœ ë‹ˆì˜¨í˜ì´')
        ]

        # ëª¨ë“  CIDë¥¼ í•©ì¹œ ë¦¬ìŠ¤íŠ¸
        all_cids = search_cids + card_cids

        # ìœ íš¨í•œ ë‹¨ê³„ì¸ì§€ í™•ì¸ (step 0ëŠ” ê¸°ì¤€ê°€ê²©ë§Œ ì„¤ì •)
        if step >= len(all_cids) + 1:
            return jsonify({'error': 'ëª¨ë“  CID ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤'}), 400

        # stepì´ 0ì´ë©´ ê¸°ì¤€ê°€ê²©ë§Œ ì„¤ì •, 1 ì´ìƒì´ë©´ ì‹¤ì œ CID ì²˜ë¦¬
        if step == 0:
            current_cid, current_name = None, "ê¸°ì¤€ê°€ê²© ì„¤ì •"
        else:
            current_cid, current_name = all_cids[step - 1]  # step 1: all_cids[0], step 2: all_cids[1] ...

        # URLì—ì„œ CID êµì²´í•˜ê³  currencyCode ìœ ì§€
        from scraper import extract_cid_from_url, scrape_prices_simple, reorder_url_parameters, set_progress, get_progress_state
        from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
        import re

        # ì›ë³¸ URLì—ì„œ currencyCode ì¶”ì¶œ
        original_currency = None
        currency_match = re.search(r'currencyCode=([^&]+)', url)
        if currency_match:
            original_currency = currency_match.group(1)

        original_cid = extract_cid_from_url(url)

        # stepì´ 0ì´ë©´ ì›ë³¸ URL ì‚¬ìš©, 1 ì´ìƒì´ë©´ CID êµì²´
        if step == 0:
            new_url = url  # ì›ë³¸ URL ê·¸ëŒ€ë¡œ ì‚¬ìš©
        else:
            if original_cid:
                new_url = url.replace(f"cid={original_cid}", f"cid={current_cid}")
            else:
                separator = "&" if "?" in url else "?"
                new_url = f"{url}{separator}cid={current_cid}"

        # currencyCodeê°€ ë°”ë€Œì—ˆë‹¤ë©´ ì›ë³¸ìœ¼ë¡œ ë³µì›
        if original_currency:
            # í˜„ì¬ URLì˜ currencyCode ì°¾ì•„ì„œ êµì²´
            current_currency_match = re.search(r'currencyCode=([^&]+)', new_url)
            if current_currency_match:
                current_currency = current_currency_match.group(1)
                if current_currency != original_currency:
                    new_url = new_url.replace(f"currencyCode={current_currency}", f"currencyCode={original_currency}")
                    app.logger.info(f"CurrencyCode ë³µì›: {current_currency} â†’ {original_currency}")
            else:
                # currencyCodeê°€ ì—†ìœ¼ë©´ ì¶”ê°€
                separator = "&" if "?" in new_url else "?"
                new_url = f"{new_url}{separator}currencyCode={original_currency}"
                app.logger.info(f"CurrencyCode ì¶”ê°€: {original_currency}")

        # URL íŒŒë¼ë©”í„°ë¥¼ ì§€ì •ëœ ìˆœì„œë¡œ ì¬ì •ë ¬
        #app.logger.info(f"ì¬ì •ë ¬ ì „ URL: {new_url}")
        new_url = reorder_url_parameters(new_url)
        #app.logger.info(f"ì¬ì •ë ¬ í›„ URL: {new_url}")

        # ì§„í–‰ ë‹¨ê³„ ì •ë³´
        if step == 0:
            is_search_phase = False  # ê¸°ì¤€ê°€ê²©ì€ ê²€ìƒ‰ì°½ ë¦¬ìŠ¤íŠ¸ì— í‘œì‹œí•˜ì§€ ì•ŠìŒ
            phase_name = "ê¸°ì¤€ê°€ê²© ì„¤ì •"
        else:
            is_search_phase = step <= len(search_cids)  # step 1ë¶€í„° search_cids ì²˜ë¦¬
            phase_name = "ê²€ìƒ‰ì°½ë¦¬ìŠ¤íŠ¸" if is_search_phase else "ì¹´ë“œë¦¬ìŠ¤íŠ¸"

        app.logger.info(f"Processing ìŠ¤í… {step+1}/{len(all_cids) + 1}: CID {current_name}({current_cid})")

        # ê¸°ì¤€ ê°€ê²© ê³„ì‚° (ì²« ë²ˆì§¸ ìŠ¤í…ì—ì„œ ì›ë³¸ URLì˜ CID ê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •)
        global global_base_price, global_base_price_cid_name, global_page_title

        print_file(f"Processing ìŠ¤í… {step+1}/{len(all_cids) + 1}: CID {current_name}({current_cid})")

        if step == 0:
            # ì²« ë²ˆì§¸ ìŠ¤í…ì—ì„œëŠ” ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
            global_base_price = None
            global_base_price_cid_name = ''
            # ì›ë³¸ URLì˜ CIDë¡œ ê¸°ì¤€ ê°€ê²© ì¶”ì¶œ
            if original_cid:
                # ì›ë³¸ URLì— CIDê°€ ìˆìœ¼ë©´ ê·¸ê²ƒìœ¼ë¡œ ê¸°ì¤€ ê°€ê²© ì¶”ì¶œ
                base_url = url  # ì›ë³¸ URL ì‚¬ìš©
                # ì›ë³¸ CIDì˜ ì´ë¦„ ì°¾ê¸°
                for cid_value, cid_name in all_cids:
                    if cid_value == original_cid:
                        global_base_price_cid_name = cid_name
                        break
                if not global_base_price_cid_name:
                    global_base_price_cid_name = f'ì›ë³¸ CID({original_cid})'
            else:
                # CIDê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ CID(ì‹œí¬ë¦¿ì°½)ë¡œ ê¸°ì¤€ ì„¤ì •
                base_url = new_url
                global_base_price_cid_name = current_name

            base_url_new = reorder_url_parameters(base_url)

            from scraper import set_progress
            set_progress(0, f"{current_name} ì‹œì‘")

            # ê¸°ì¤€ ê°€ê²© ìŠ¤í¬ë˜í•‘
            import time
            start_time = time.time()
            #time.sleep(1)

            print_file(f"ê¸°ì¤€ ê°€ê²© ìŠ¤í¬ë˜í•‘ ì‹œì‘: {base_url_new}")
            
            base_resp = scrape_prices_simple(
                base_url_new,
                original_currency_code=original_currency,
                progress_cb=lambda pct, msg=None: set_progress(pct, f"ê¸°ì¤€ê°€ {msg or ''}".strip())
            )

            global_page_title = base_resp.get('page_title', '')
            app.logger.info(f"page title : {global_page_title}")
            print_file(f"page title : {global_page_title}")

            
            base_prices = base_resp.get('prices', [])
            
            if base_prices:
                base_price_str = base_prices[0]['price']
                # ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ê¸°ì¤€ ê°€ê²© ì„¤ì •
                import re
                base_price_match = re.search(r'[\d,]+', base_price_str)
                if base_price_match:
                    global_base_price = int(base_price_match.group().replace(',', ''))
                    app.logger.info(f"ê¸°ì¤€ ê°€ê²© ì„¤ì •: {base_price_str} ({global_base_price}) - {global_base_price_cid_name}")
                    print_file(f"ê¸°ì¤€ ê°€ê²© ì„¤ì •: {base_price_str} ({global_base_price}) - {global_base_price_cid_name}")

        # stepì´ 0ì´ë©´ ê¸°ì¤€ê°€ê²©ë§Œ ì„¤ì •í•˜ê³  ë°”ë¡œ ë¦¬í„´
        if step == 0:
            progress = get_progress_state()
            result = {
                'step': step + 1,
                'total_steps': len(all_cids) + 1,  # step 0ë„ í¬í•¨
                'cid': None,
                'cid_name': current_name,
                'url': new_url,
                'prices': [],
                'found_count': 0,
                'process_time': 0,
                'has_next': True,
                'next_step': 1,
                'is_search_phase': is_search_phase,
                'phase_name': phase_name,
                'search_phase_completed': False,
                'download_link': None,
                'download_filename': None,
                'base_price': global_base_price,
                'base_price_cid_name': global_base_price_cid_name,
                'current_price': None,
                'discount_percentage': None,
                'subprogress_pct': progress.get('pct', 100),
                'subprogress_msg': progress.get('msg', 'ê¸°ì¤€ê°€ê²© ì„¤ì • ì™„ë£Œ'),
                'page_title': global_page_title
            }
            return jsonify(result)

        # í˜„ì¬ CID ìŠ¤í¬ë˜í•‘ ì‹¤í–‰ (step 1 ì´ìƒì—ì„œë§Œ)
        import time
        start_time = time.time()
        #time.sleep(1)
        print_file(f"í˜„ì¬ CID ìŠ¤í¬ë˜í•‘ ì‹œì‘: {new_url}")
        resp = scrape_prices_simple(
            new_url,
            original_currency_code=original_currency,
            progress_cb=lambda pct, msg=None: set_progress(pct, f"{current_name} {msg or ''}".strip())
        )
        # ì‹¤íŒ¨ ì‹œ 1íšŒ ì¬ì‹œë„ ê·¸ëŒ€ë¡œ ìœ ì§€
        if len(resp.get('prices', [])) == 0:
            resp = scrape_prices_simple(
                new_url,
                original_currency_code=original_currency,
                progress_cb=lambda pct, msg=None: set_progress(pct, f"{current_name} {msg or ''}".strip())
            )

        prices = resp.get('prices', [])
        global_page_title = resp.get('page_title', '')

        process_time = time.time() - start_time

        # í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±
        download_filename = f"page_text_cid_{current_cid}.txt"
        download_link = f"/download/{download_filename}"

        # í• ì¸ìœ¨ ê³„ì‚°
        discount_percentage = None
        current_price = None

        print(f"global_base_price: {global_base_price}")
        print(f"prices: {prices}")
        if prices and global_base_price:
            current_price_str = prices[0]['price']
            # ìˆ«ìë§Œ ì¶”ì¶œ
            import re
            current_price_match = re.search(r'[\d,]+', current_price_str)
            print(f"current_price_match: {current_price_match}")
            if current_price_match:
                current_price = int(current_price_match.group().replace(',', ''))
                if current_price < global_base_price:
                    discount_percentage = round(((global_base_price - current_price) / global_base_price) * 100, 1)
                    app.logger.info(f"í• ì¸ìœ¨: {discount_percentage}% (ê¸°ì¤€: {global_base_price}, í˜„ì¬: {current_price})")
                elif current_price > global_base_price:
                    # ë” ë¹„ì‹¼ ê²½ìš° ìŒìˆ˜ë¡œ í‘œì‹œ (ì˜ˆ: -5%)
                    discount_percentage = round(((global_base_price - current_price) / global_base_price) * 100, 1)
                    app.logger.info(f"ê°€ê²© ìƒìŠ¹: {discount_percentage}% (ê¸°ì¤€: {global_base_price}, í˜„ì¬: {current_price})")
                else:
                    discount_percentage = 0

                print(f"discount_percentage: {discount_percentage}")

        progress = get_progress_state()

        print(f"progress: {progress}")
        print(f"step: {step}")
        print(f"len(all_cids): {len(all_cids)}")
                
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'step': step + 1,
            'total_steps': len(all_cids) + 1,  # step 0ë„ í¬í•¨
            'cid': current_cid,
            'cid_name': current_name,
            'url': new_url,
            'prices': prices,
            'found_count': len(prices),
            'process_time': round(process_time, 1),
            'has_next': step + 1 <= len(all_cids),  # stepì´ len(all_cids)ê¹Œì§€ ê°€ëŠ¥
            'next_step': step + 1 if step + 1 <= len(all_cids) else None,
            'is_search_phase': is_search_phase,
            'phase_name': phase_name,
            'search_phase_completed': step == len(search_cids),  # stepì´ search_cids ê¸¸ì´ì™€ ê°™ì„ ë•Œ ì™„ë£Œ
            'download_link': download_link,
            'download_filename': download_filename,
            'base_price': global_base_price,
            'base_price_cid_name': global_base_price_cid_name,
            'current_price': current_price,
            'discount_percentage': discount_percentage,
            'subprogress_pct': progress.get('pct', 0),
            'subprogress_msg': progress.get('msg', ''),
            'page_title': global_page_title
        }

        return jsonify(result)

    except Exception as e:
        app.logger.error(f"Error in scraping: {str(e)}")
        return jsonify({
            'error': f'ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}'
        }), 500

@app.route('/guide')
def guide():
    """ì‚¬ìš©ë°©ë²• ê°€ì´ë“œ í˜ì´ì§€"""
    lang = request.args.get('lang', 'ko')  # ê¸°ë³¸ê°’ì€ í•œêµ­ì–´
    return render_template('guide.html', lang=lang)

@app.route('/download/<filename>')
def download_file(filename):
    """í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        import os
        file_path = os.path.join('downloads', filename)

        if not os.path.exists(file_path):
            return jsonify({'error': 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404

        return send_file(
            file_path,
            as_attachment=True,
            download_name=filename,
            mimetype='text/plain; charset=utf-8'
        )

    except Exception as e:
        app.logger.error(f"Error downloading file: {str(e)}")
        return jsonify({'error': f'ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}'}), 500

@app.route('/test')
def test_page():
    """í…ŒìŠ¤íŠ¸ í˜ì´ì§€ ë¼ìš°íŠ¸"""
    return send_file('static/pages/test.html')

@app.route('/info')
def info_page():
    """ì •ë³´ í˜ì´ì§€ ë¼ìš°íŠ¸"""
    return send_file('static/pages/info.html')

@app.route('/split')
def split_view_page():
    """ë¶„í•  ë·° í˜ì´ì§€ ë¼ìš°íŠ¸"""
    return send_file('static/pages/split_view.html')

@app.route('/progress', methods=['GET'])
def progress_state():
    from scraper import get_progress_state
    return jsonify(get_progress_state())

@app.route('/status')
def status_page():
    """ì‹œìŠ¤í…œ ìƒíƒœ í˜ì´ì§€"""
    import platform
    import sys
    import os

    status_info = {
        'app_status': 'Running',
        'python_version': sys.version,
        'platform': platform.platform(),
        'server_port': '8000 (í”„ë¡ì‹œ ì—°ê²°)',
        'domain': 'https://agodamagic.cafe24.com',
        'static_pages': [
            '/test - í…ŒìŠ¤íŠ¸ í˜ì´ì§€',
            '/info - ì •ë³´ í˜ì´ì§€',
            '/split - ë¶„í•  ë·° í˜ì´ì§€', 
            '/status - ìƒíƒœ í˜ì´ì§€',
            '/static/pages/test.html - ì§ì ‘ ì ‘ê·¼',
            '/static/pages/info.html - ì§ì ‘ ì ‘ê·¼',
            '/static/pages/split_view.html - ì§ì ‘ ì ‘ê·¼'
        ]
    }

    # ê°„ë‹¨í•œ HTML ì‘ë‹µ
    html = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>ì‹œìŠ¤í…œ ìƒíƒœ - agoda-magic-price</title>
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
        <style>
            body {{ background: linear-gradient(135deg, #2d3748 0%, #4a5568 100%); min-height: 100vh; color: white; }}
            .card {{ background: rgba(255,255,255,0.1); border: none; border-radius: 15px; }}
            .btn-custom {{ background: linear-gradient(45deg, #4299e1, #3182ce); border: none; color: white; }}
        </style>
    </head>
    <body>
        <div class="container py-5">
            <div class="row justify-content-center">
                <div class="col-md-8">
                    <div class="card">
                        <div class="card-body p-5">
                            <h1 class="text-center mb-4">âš™ï¸ ì‹œìŠ¤í…œ ìƒíƒœ</h1>
                            <div class="row">
                                <div class="col-md-6">
                                    <h5>ğŸ“Š ì•± ìƒíƒœ</h5>
                                    <p>âœ… {status_info['app_status']}</p>
                                    <h5>ğŸŒ ì ‘ì† ì •ë³´</h5>
                                    <p>ë„ë©”ì¸: {status_info['domain']}</p>
                                    <p>í¬íŠ¸: {status_info['server_port']}</p>
                                </div>
                                <div class="col-md-6">
                                    <h5>ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´</h5>
                                    <p>Python: {status_info['python_version'].split()[0]}</p>
                                    <p>OS: {status_info['platform']}</p>
                                </div>
                            </div>
                            <div class="mt-4">
                                <h5>ğŸ“„ ì‚¬ìš© ê°€ëŠ¥í•œ í˜ì´ì§€</h5>
                                <ul class="list-unstyled">
                                    {''.join(f'<li>â€¢ {page}</li>' for page in status_info['static_pages'])}
                                </ul>
                            </div>
                            <div class="text-center mt-4">
                                <a href="/" class="btn btn-custom me-2">ë©”ì¸ í˜ì´ì§€</a>
                                <a href="/test" class="btn btn-custom me-2">í…ŒìŠ¤íŠ¸ í˜ì´ì§€</a>
                                <a href="/info" class="btn btn-custom me-2">ì •ë³´ í˜ì´ì§€</a>
                                <a href="/split" class="btn btn-custom">ë¶„í•  ë·°</a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </body>
    </html>
    """
    return html

@app.route('/cancel', methods=['POST'])
def cancel_analysis():
    """ë¶„ì„ ì¤‘ë‹¨ ìš”ì²­ ì²˜ë¦¬"""
    global is_cancelled
    is_cancelled = True
    app.logger.info("ë¶„ì„ ì¤‘ë‹¨ ìš”ì²­ ë°›ìŒ")
    return jsonify({'status': 'cancelled', 'message': 'ë¶„ì„ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.'})


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)