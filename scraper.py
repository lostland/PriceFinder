import re
from bs4 import BeautifulSoup
import logging
import requests
import time
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse

def scrape_prices_simple(url, original_currency_code=None):
    """
    ë‹¨ìˆœí•˜ê³  ë¹ ë¥¸ ê°€ê²© ìŠ¤í¬ë˜í•‘ - ì´ë¯¸ì§€ ì²˜ë¦¬ ì—†ìŒ
    Returns a list of dictionaries containing price and context information
    original_currency_code: ì›ë³¸ URLì˜ í†µí™” ì½”ë“œ (ì˜ˆ: USD, KRW, THB)
    """
    try:
        # ìµœì í™”ëœ Selenium ì‚¬ìš© - AgodaëŠ” JavaScript ì‹¤í–‰ í•„ìš”
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--disable-images')  # ì´ë¯¸ì§€ ì°¨ë‹¨ìœ¼ë¡œ ì†ë„ í–¥ìƒ
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--window-size=800,600')  # ì‘ì€ ì°½ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
        chrome_options.add_argument('--disable-logging')
        chrome_options.add_argument('--log-level=3')
        
        # ë´‡ íƒì§€ ìš°íšŒ
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        chrome_options.add_experimental_option('excludeSwitches', ['enable-automation'])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        print(f"ìŠ¤í¬ë˜í•‘ ì‚¬ìš© URL: {url}")
        
        start_time = time.time()
        
        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(15)  # 15ì´ˆ íƒ€ì„ì•„ì›ƒ
        
        # ë´‡ íƒì§€ ìš°íšŒ ìŠ¤í¬ë¦½íŠ¸
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        try:
            driver.get(url)
            # ë¶ˆí•„ìš”í•œ ëŒ€ê¸° ì‹œê°„ ì œê±° - í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ í›„ ë°”ë¡œ ì§„í–‰
            page_source = driver.page_source
            
        finally:
            driver.quit()
        
        load_time = time.time() - start_time
        print(f"âœ… í˜ì´ì§€ ë¡œë”© ì™„ë£Œ: {load_time:.2f}ì´ˆ")
        
        # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
        soup = BeautifulSoup(page_source, 'html.parser')
        all_text = soup.get_text()
        
        print(f"í˜ì´ì§€ í¬ê¸°: {len(all_text)} ê¸€ì, {len(all_text.encode('utf-8'))} bytes")
        
        # ë‹¨ê³„ë³„ ë””ë²„ê·¸ íŒŒì¼ ìƒì„± - ì–´ë””ì„œ ë¬¸ì œì¸ì§€ ì •í™•íˆ íŒŒì•…
        debug_filepath = None
        try:
            print(f"ğŸš€ íŒŒì¼ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
            
            # ë¡œê·¸ íŒŒì¼ì—ë„ ì§ì ‘ ê¸°ë¡
            try:
                with open('/tmp/agoda_debug.log', 'a', encoding='utf-8') as log_f:
                    log_f.write(f"\n=== {time.strftime('%Y-%m-%d %H:%M:%S')} ===\n")
                    log_f.write(f"ğŸš€ íŒŒì¼ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘\n")
            except:
                pass  # ë¡œê·¸ ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ
            
            import os
            print(f"ğŸ“‚ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
            print(f"âœï¸  í˜„ì¬ ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ: {os.access('.', os.W_OK)}")
            
            if not os.path.exists('downloads'):
                print(f"ğŸ“ downloads ë””ë ‰í† ë¦¬ ìƒì„± ì¤‘...")
                os.makedirs('downloads')
                print(f"âœ… downloads ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ")
            else:
                print(f"âœ… downloads ë””ë ‰í† ë¦¬ ì´ë¯¸ ì¡´ì¬")
            
            print(f"âœï¸  downloads ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ: {os.access('downloads', os.W_OK)}")
            
            # CID ì •ë³´ ì¶”ì¶œ
            print(f"ğŸ¯ URLì—ì„œ CID ì¶”ì¶œ ì¤‘: {url}")
            cid_match = re.search(r'cid=([^&]+)', url)
            cid_value = cid_match.group(1) if cid_match else 'unknown'
            print(f"ğŸ¯ ì¶”ì¶œëœ CID ê°’: {cid_value}")
            
            # íŒŒì¼ëª… ìƒì„±
            filename = f"page_text_cid_{cid_value}.txt"
            debug_filepath = os.path.join('downloads', filename)
            print(f"ğŸ“ ìƒì„±í•  íŒŒì¼ ê²½ë¡œ: {debug_filepath}")
            
            print(f"ğŸ“ 1ë‹¨ê³„: ê¸°ë³¸ íŒŒì¼ ìƒì„± ì‹œì‘ - {debug_filepath}")
            
            # 1ë‹¨ê³„: ê¸°ë³¸ í—¤ë” íŒŒì¼ ìƒì„±
            try:
                with open(debug_filepath, 'w', encoding='utf-8') as f:
                    f.write("="*80 + "\n")
                    f.write("ğŸ” AGODA MAGIC PRICE - ìƒì„¸ ë””ë²„ê·¸ ì •ë³´\n")
                    f.write("="*80 + "\n")
                    f.write(f"ğŸ“… ìŠ¤í¬ë˜í•‘ ì¼ì‹œ: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"ğŸŒ ìš”ì²­ URL: {url}\n")
                    f.write(f"ğŸ¯ CID ê°’: {cid_value}\n")
                    f.write("âœ… 1ë‹¨ê³„ ì™„ë£Œ: ê¸°ë³¸ íŒŒì¼ ìƒì„±ë¨\n")
                
                print(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ: ê¸°ë³¸ íŒŒì¼ ìƒì„±ë¨")
                
                # íŒŒì¼ì´ ì‹¤ì œë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ ì¦‰ì‹œ í™•ì¸
                if os.path.exists(debug_filepath):
                    file_size = os.path.getsize(debug_filepath)
                    print(f"âœ… íŒŒì¼ ìƒì„± í™•ì¸ë¨: {file_size} bytes")
                    
                    # ë¡œê·¸ íŒŒì¼ì—ë„ ê¸°ë¡
                    try:
                        with open('/tmp/agoda_debug.log', 'a', encoding='utf-8') as log_f:
                            log_f.write(f"âœ… íŒŒì¼ ìƒì„± í™•ì¸ë¨: {file_size} bytes\n")
                            log_f.write(f"ğŸ“ íŒŒì¼ ê²½ë¡œ: {debug_filepath}\n")
                    except:
                        pass
                else:
                    print(f"âŒ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ!")
                    
                    # ë¡œê·¸ íŒŒì¼ì—ë„ ê¸°ë¡
                    try:
                        with open('/tmp/agoda_debug.log', 'a', encoding='utf-8') as log_f:
                            log_f.write(f"âŒ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ!\n")
                            log_f.write(f"ğŸ“ ì‹œë„í•œ ê²½ë¡œ: {debug_filepath}\n")
                    except:
                        pass
                    
            except Exception as write_error:
                print(f"âŒ íŒŒì¼ ì“°ê¸° ì¤‘ ì˜¤ë¥˜: {write_error}")
                import traceback
                traceback.print_exc()
                debug_filepath = None
            
            # 2ë‹¨ê³„: ì„±ëŠ¥ ì •ë³´ ì¶”ê°€
            if debug_filepath:  # debug_filepathê°€ Noneì´ ì•„ë‹ ë•Œë§Œ ì‹¤í–‰
                try:
                    print(f"ğŸ“Š 2ë‹¨ê³„: ì„±ëŠ¥ ì •ë³´ ì¶”ê°€ ì‹œì‘")
                    with open(debug_filepath, 'a', encoding='utf-8') as f:
                        f.write(f"ğŸ“Š ì›ë³¸ í˜ì´ì§€ í¬ê¸°: {len(page_source):,} ê¸€ì\n")
                        f.write(f"ğŸ“ í…ìŠ¤íŠ¸ í¬ê¸°: {len(all_text):,} ê¸€ì\n")
                        f.write(f"ğŸ’¾ íŒŒì¼ í¬ê¸°: {len(all_text.encode('utf-8')):,} bytes\n")
                        f.write(f"âš¡ ë¡œë”© ì‹œê°„: {load_time:.2f}ì´ˆ\n")
                        f.write("âœ… 2ë‹¨ê³„ ì™„ë£Œ: ì„±ëŠ¥ ì •ë³´ ì¶”ê°€ë¨\n")
                    
                    print(f"âœ… 2ë‹¨ê³„ ì™„ë£Œ: ì„±ëŠ¥ ì •ë³´ ì¶”ê°€ë¨")
                    
                except Exception as append_error:
                    print(f"âŒ 2ë‹¨ê³„ ì„±ëŠ¥ ì •ë³´ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {append_error}")
                    import traceback
                    traceback.print_exc()
            else:
                print(f"âŒ 2ë‹¨ê³„ ê±´ë„ˆëœ€: debug_filepathê°€ Noneì„")
            
        except Exception as step_error:
            print(f"âŒ ì „ì²´ íŒŒì¼ ìƒì„± í”„ë¡œì„¸ìŠ¤ì—ì„œ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {step_error}")
            import traceback
            traceback.print_exc()
            debug_filepath = None
            
        # 3ë‹¨ê³„: ê°€ê²© ë¶„ì„ ì •ë³´ ì¶”ê°€
        try:
            if debug_filepath:
                with open(debug_filepath, 'a', encoding='utf-8') as f:
                    # ì‹œì‘ê°€ ê²€ìƒ‰ ê²°ê³¼
                    pattern = r'ì‹œì‘ê°€\s*â‚©\s*(\d{1,3}(?:,\d{3})+)'
                    match = re.search(pattern, all_text)
                    if match:
                        f.write(f"âœ… ì‹œì‘ê°€ ë°œê²¬: â‚©{match.group(1)}\n")
                    else:
                        f.write("âŒ ì‹œì‘ê°€ íŒ¨í„´ ì‹¤íŒ¨\n")
                    
                    # í†µí™” ì •ë³´ ë¶„ì„
                    krw_count = len(re.findall(r'â‚©', all_text))
                    usd_count = len(re.findall(r'\$', all_text))
                    thb_count = len(re.findall(r'à¸¿', all_text))
                    f.write(f"ğŸ’± í†µí™” ê¸°í˜¸ ê°œìˆ˜: â‚©({krw_count}), $({usd_count}), à¸¿({thb_count})\n")
                    
                    # ìˆ«ì íŒ¨í„´ ë¶„ì„
                    price_numbers = re.findall(r'\d{1,3}(?:,\d{3})+', all_text)
                    f.write(f"ğŸ”¢ í° ìˆ«ì íŒ¨í„´: {len(price_numbers)}ê°œ ë°œê²¬\n")
                    if price_numbers:
                        f.write(f"    ì˜ˆì‹œ: {', '.join(price_numbers[:5])}\n")
                    
                    f.write("âœ… 3ë‹¨ê³„ ì™„ë£Œ: ê°€ê²© ë¶„ì„ ì •ë³´ ì¶”ê°€ë¨\n")
                
                print(f"âœ… 3ë‹¨ê³„ ì™„ë£Œ: ê°€ê²© ë¶„ì„ ì •ë³´ ì¶”ê°€ë¨")
                
        except Exception as analysis_error:
            print(f"âŒ 3ë‹¨ê³„ ì˜¤ë¥˜: {analysis_error}")
            
        # 4ë‹¨ê³„: ê¸°ìˆ  ì •ë³´ ë° í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ê°€
        try:
            if debug_filepath:
                with open(debug_filepath, 'a', encoding='utf-8') as f:
                    # ë¸Œë¼ìš°ì € ì •ë³´
                    f.write(f"ğŸŒ Chrome ì˜µì…˜: headless, no-images, 800x600\n")
                    f.write(f"ğŸš€ ìµœì í™”: ì´ë¯¸ì§€ ì°¨ë‹¨, í”ŒëŸ¬ê·¸ì¸ ì°¨ë‹¨\n")
                    f.write("âœ… 4ë‹¨ê³„ ì™„ë£Œ: ê¸°ìˆ  ì •ë³´ ì¶”ê°€ë¨\n")
                    
                    f.write("="*80 + "\n")
                    f.write("ğŸ“„ ì‹¤ì œ í˜ì´ì§€ í…ìŠ¤íŠ¸ ë‚´ìš©\n")
                    f.write("="*80 + "\n\n")
                    f.write(all_text)
                    f.write("\n\nâœ… 5ë‹¨ê³„ ì™„ë£Œ: ì „ì²´ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ê°€ë¨")
                
                print(f"âœ… 4-5ë‹¨ê³„ ì™„ë£Œ: ì „ì²´ ë””ë²„ê·¸ íŒŒì¼ ì™„ì„±ë¨")
                print(f"ğŸ“ ìµœì¢… ë””ë²„ê·¸ íŒŒì¼: {debug_filepath}")
                
        except Exception as final_error:
            print(f"âŒ 4-5ë‹¨ê³„ ì˜¤ë¥˜: {final_error}")
        
        # ì‹œì‘ê°€ ê²€ìƒ‰ ì‹œë„
        starting_price = None
        pattern = r'ì‹œì‘ê°€\s*â‚©\s*(\d{1,3}(?:,\d{3})+)'
        match = re.search(pattern, all_text)
        
        if match:
            price_number = match.group(1)
            starting_price = {
                'price': f"â‚©{price_number}",
                'context': f"ì‹œì‘ê°€ â‚©{price_number}",
                'source': 'starting_price_direct'
            }
            print(f"âœ… ì‹œì‘ê°€ ë°œê²¬: {starting_price['price']}")
            return [starting_price]
        else:
            print("âŒ ì‹œì‘ê°€ íŒ¨í„´ ì‹¤íŒ¨ - ì¼ë°˜ ê°€ê²© ê²€ìƒ‰ ì§„í–‰")
        
        prices_found = []
        seen_prices = set()
        
        # 1ë‹¨ê³„: íŠ¹ì • ê°€ê²© ìš”ì†Œë“¤ë¶€í„° ìš°ì„  ì°¾ê¸° (ì‹¤ì œ ì˜ˆì•½ ê°€ê²©)
        price_selectors = [
            # ì¼ë°˜ì ì¸ í˜¸í…” ì˜ˆì•½ ì‚¬ì´íŠ¸ ê°€ê²© í´ë˜ìŠ¤ë“¤
            '[class*="price"]',
            '[class*="cost"]', 
            '[class*="rate"]',
            '[class*="amount"]',
            '[class*="total"]',
            '[class*="nightly"]',
            '[data-testid*="price"]',
            '[data-price]',
            # ë” êµ¬ì²´ì ì¸ ì…€ë ‰í„°ë“¤
            '.room-price',
            '.hotel-price',
            '.booking-price',
            '.final-price'
        ]
        
        for selector in price_selectors:
            try:
                elements = soup.select(selector)
                for element in elements:
                    text = element.get_text(strip=True)
                    
                    # ê°€ê²© íŒ¨í„´ ì°¾ê¸°
                    price_patterns = [
                        r'(\$[1-9]\d{2,4}(?:\.\d{2})?)',  # $100-99999.99
                        r'([1-9]\d{2,4}(?:\.\d{2})?\s*USD)',  # 123.45 USD
                        r'(\$[1-9]\d{1,2})',  # $10-999
                    ]
                    
                    for pattern in price_patterns:
                        matches = re.findall(pattern, text, re.IGNORECASE)
                        for price_text in matches:
                            if price_text not in seen_prices:
                                # í‰ê· ê°€ê²© ì œì™¸
                                parent_text = element.parent.get_text(strip=True).lower() if element.parent else text.lower()
                                
                                is_average_price = (
                                    'average' in parent_text or
                                    'avg' in parent_text or
                                    'stands at' in parent_text or
                                    'typical' in parent_text
                                )
                                
                                if not is_average_price:
                                    seen_prices.add(price_text)
                                    prices_found.append({
                                        'price': price_text,
                                        'context': f"Found in {selector}: {text[:100]}",
                                        'source': 'targeted_element'
                                    })
                                    
                                    if len(prices_found) >= 3:
                                        break
                        
                        if len(prices_found) >= 3:
                            break
                    
                    if len(prices_found) >= 3:
                        break
            except Exception:
                continue
            
            if len(prices_found) >= 3:
                break
        
        # 2ë‹¨ê³„: íŠ¹ì • ìš”ì†Œì—ì„œ ëª» ì°¾ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰
        if len(prices_found) < 2:
            # scriptì™€ style íƒœê·¸ ì œê±°
            for element in soup(["script", "style"]):
                element.decompose()
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text_content = soup.get_text()
            
            # ë” ì ê·¹ì ì¸ ê°€ê²© íŒ¨í„´ ê²€ìƒ‰
            price_patterns = [
                # ì‹¤ì œ ì˜ˆì•½ ê°€ê²©ì´ ë‚˜ì˜¬ ê°€ëŠ¥ì„±ì´ ë†’ì€ íŒ¨í„´ë“¤
                r'(\$[1-9]\d{2,4}(?:\.\d{2})?)\s*(?:per night|night|/night)',  # $123 per night
                r'(\$[1-9]\d{2,4}(?:\.\d{2})?)\s*(?:total|Total)',  # $123 total
                r'(?:from|From)\s*(\$[1-9]\d{2,4}(?:\.\d{2})?)',  # from $123
                r'(\$[1-9]\d{2,4}(?:\.\d{2})?)',  # ì¼ë°˜ $123
                r'([1-9]\d{2,4}(?:\.\d{2})?\s*USD)',  # 123 USD
            ]
            
            for pattern in price_patterns:
                matches = re.finditer(pattern, text_content, re.IGNORECASE)
                
                for match in matches:
                    price_text = match.group(1).strip()
                    
                    if price_text in seen_prices:
                        continue
                    
                    # ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    start_pos = max(0, match.start() - 80)
                    end_pos = min(len(text_content), match.end() + 80)
                    context = text_content[start_pos:end_pos].strip()
                    context_lower = context.lower()
                    
                    # í‰ê· ê°€ê²© ë° ê¸°íƒ€ ë¶ˆí•„ìš”í•œ ê°€ê²© ì œì™¸
                    skip_keywords = [
                        'with an average room price of',
                        'which stands at',
                        'average room price',
                        'typical price',
                        'generally costs',
                        'usually costs'
                    ]
                    
                    should_skip = any(keyword in context_lower for keyword in skip_keywords)
                    
                    if should_skip:
                        continue
                    
                    context = re.sub(r'\s+', ' ', context)[:150]
                    
                    seen_prices.add(price_text)
                    prices_found.append({
                        'price': price_text,
                        'context': context,
                        'source': 'text_search'
                    })
                    
                    # ìµœëŒ€ 5ê°œë¡œ ì œí•œ
                    if len(prices_found) >= 5:
                        break
                
                if len(prices_found) >= 5:
                    break
        
        # ë””ë²„ê·¸: ì‹¤ì œ í˜ì´ì§€ì— ì–´ë–¤ ê°€ê²© ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
        # (ì‹¤ì œ ë°°í¬ì‹œì—ëŠ” ì œê±°)
        debug_patterns = [
            r'(\$\d+)',  # ëª¨ë“  $ ê°€ê²©
            r'(\d+\.\d+)',  # ì†Œìˆ˜ì  ìˆ«ì
            r'(USD)',  # USD í…ìŠ¤íŠ¸
            r'(price|Price|PRICE)',  # price í…ìŠ¤íŠ¸
            r'(total|Total)',  # total í…ìŠ¤íŠ¸
            r'(night|Night)',  # night í…ìŠ¤íŠ¸
        ]
        
        debug_info = {}
        all_text = soup.get_text()
        
        # 5KB ì œí•œ: í…ìŠ¤íŠ¸ê°€ 5KBë¥¼ ë„˜ìœ¼ë©´ 5KBê¹Œì§€ë§Œ ìë¥´ê³  ì¦‰ì‹œ ì¢…ë£Œ
        text_size_bytes = len(all_text.encode('utf-8'))
        if text_size_bytes > 5 * 1024:  # 5KB = 5 * 1024 bytes
            # UTF-8 ê¸°ì¤€ 5KBê¹Œì§€ë§Œ ìë¥´ê¸° (ì•ˆì „í•˜ê²Œ)
            truncated_text = all_text
            while len(truncated_text.encode('utf-8')) > 5 * 1024:
                truncated_text = truncated_text[:-100]  # 100ê¸€ìì”© ì¤„ì´ê¸°
            all_text = truncated_text + "... [5KB ì œí•œìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¼ë¶€ë§Œ ìˆ˜ì§‘ë¨]"
            
            # ì¦‰ì‹œ íŒŒì¼ ì €ì¥í•˜ê³  ê°€ê²© ë¶„ì„ ê±´ë„ˆë›°ê¸°
            try:
                import os
                if not os.path.exists('downloads'):
                    os.makedirs('downloads')
                
                # CID ì •ë³´ ì¶”ì¶œ
                cid_match = re.search(r'cid=([^&]+)', url)
                cid_value = cid_match.group(1) if cid_match else 'unknown'
                
                # íŒŒì¼ëª… ìƒì„±
                filename = f"page_text_cid_{cid_value}.txt"
                filepath = os.path.join('downloads', filename)
                
                # ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥ (ë””ë²„ê·¸ ì •ë³´ ëŒ€í­ ì¶”ê°€)
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write("="*80 + "\n")
                    f.write("ğŸ” AGODA MAGIC PRICE - ìƒì„¸ ë””ë²„ê·¸ ì •ë³´\n")
                    f.write("="*80 + "\n")
                    f.write(f"ğŸ“… ìŠ¤í¬ë˜í•‘ ì¼ì‹œ: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"ğŸŒ ìš”ì²­ URL: {url}\n")
                    f.write(f"ğŸ¯ CID ê°’: {cid_value}\n")
                    f.write(f"ğŸ“Š ì›ë³¸ í˜ì´ì§€ í¬ê¸°: {len(page_source):,} ê¸€ì\n")
                    f.write(f"ğŸ“ í…ìŠ¤íŠ¸ í¬ê¸°: {len(all_text):,} ê¸€ì\n")
                    f.write(f"ğŸ’¾ íŒŒì¼ í¬ê¸°: {len(all_text.encode('utf-8')):,} bytes\n")
                    f.write(f"âš¡ ë¡œë”© ì‹œê°„: {load_time:.2f}ì´ˆ\n")
                    f.write(f"ğŸš« 5KB ì œí•œ: ì ìš©ë¨ (ì›ë³¸ í¬ê¸° ì´ˆê³¼)\n")
                    
                    # ì‹œì‘ê°€ ê²€ìƒ‰ ê²°ê³¼
                    pattern = r'ì‹œì‘ê°€\s*â‚©\s*(\d{1,3}(?:,\d{3})+)'
                    match = re.search(pattern, all_text)
                    if match:
                        f.write(f"âœ… ì‹œì‘ê°€ ë°œê²¬: â‚©{match.group(1)}\n")
                    else:
                        f.write("âŒ ì‹œì‘ê°€ íŒ¨í„´ ì‹¤íŒ¨\n")
                    
                    # í†µí™” ì •ë³´ ë¶„ì„
                    krw_count = len(re.findall(r'â‚©', all_text))
                    usd_count = len(re.findall(r'\$', all_text))
                    thb_count = len(re.findall(r'à¸¿', all_text))
                    f.write(f"ğŸ’± í†µí™” ê¸°í˜¸ ê°œìˆ˜: â‚©({krw_count}), $({usd_count}), à¸¿({thb_count})\n")
                    
                    # ìˆ«ì íŒ¨í„´ ë¶„ì„
                    price_numbers = re.findall(r'\d{1,3}(?:,\d{3})+', all_text)
                    f.write(f"ğŸ”¢ í° ìˆ«ì íŒ¨í„´: {len(price_numbers)}ê°œ ë°œê²¬\n")
                    if price_numbers:
                        f.write(f"    ì˜ˆì‹œ: {', '.join(price_numbers[:5])}\n")
                    
                    # ë¸Œë¼ìš°ì € ì •ë³´
                    f.write(f"ğŸŒ Chrome ì˜µì…˜: headless, no-images, 800x600\n")
                    f.write(f"ğŸš€ ìµœì í™”: ì´ë¯¸ì§€ ì°¨ë‹¨, í”ŒëŸ¬ê·¸ì¸ ì°¨ë‹¨\n")
                    
                    f.write("="*80 + "\n")
                    f.write("ğŸ“„ ì‹¤ì œ í˜ì´ì§€ í…ìŠ¤íŠ¸ ë‚´ìš©\n")
                    f.write("="*80 + "\n\n")
                    f.write(all_text)
                
                print(f"5KB ì œí•œ - í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ë¨: {filepath}")
                
            except Exception as save_error:
                print(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {save_error}")
            
            # txt íŒŒì¼ì—ì„œ "ì‹œì‘ê°€" ë’¤ì˜ ê°€ê²© ì°¾ê¸°
            starting_price = None
            try:
                # ë” ê°„ë‹¨í•˜ê³  í™•ì‹¤í•œ íŒ¨í„´ìœ¼ë¡œ ìˆ˜ì •
                simple_pattern = r'ì‹œì‘ê°€\s*â‚©\s*(\d{1,3}(?:,\d{3})+)'
                match = re.search(simple_pattern, all_text)
                
                if match:
                    price_number = match.group(1)  # ìˆ«ì ë¶€ë¶„ë§Œ (ì˜ˆ: "63,084")
                    starting_price = {
                        'price': f"â‚©{price_number}",  # â‚© í¬í•¨í•œ ì™„ì „í•œ ê°€ê²©
                        'context': f"ì‹œì‘ê°€ â‚©{price_number}",
                        'source': 'starting_price_from_file'
                    }
                    print(f"âœ… ì‹œì‘ê°€ ë°œê²¬: {starting_price['price']}")
                else:
                    print("âŒ ì‹œì‘ê°€ íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨")
                
            except Exception as e:
                print(f"ì‹œì‘ê°€ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            
            # ì‹œì‘ê°€ë¥¼ ì°¾ì•˜ìœ¼ë©´ ë°˜í™˜, ëª» ì°¾ì•˜ìœ¼ë©´ ë¹ˆ ê²°ê³¼
            if starting_price:
                return [starting_price]
            else:
                print("âŒ ì‹œì‘ê°€ë¥¼ ì°¾ì§€ ëª»í•¨ - ë¹ˆ ê²°ê³¼ ë°˜í™˜")
                return []
        
        for pattern in debug_patterns:
            matches = re.findall(pattern, all_text, re.IGNORECASE)
            if matches:
                debug_info[pattern] = matches[:10]  # ì²˜ìŒ 10ê°œë§Œ
        
        # ë” ê´‘ë²”ìœ„í•œ ê°€ê²© íŒ¨í„´ ê²€ìƒ‰
        all_price_patterns = [
            # ë‹¬ëŸ¬ íŒ¨í„´
            r'(\$[1-9]\d{2,4}(?:\.\d{2})?)',  # $100-99999.99
            r'(\$[1-9]\d{1,2})',  # $10-999
            # USD íŒ¨í„´
            r'([1-9]\d{2,4}(?:\.\d{2})?\s*USD)',  # 100-9999.99 USD
            r'USD\s*([1-9]\d{2,4}(?:\.\d{2})?)',  # USD 100-9999.99
            r'USD\s*([1-9]\d{1,2})',  # USD 10-999
            # ìˆœìˆ˜ ìˆ«ì íŒ¨í„´ (ê°€ê²©ì¼ ê°€ëŠ¥ì„±)
            r'\b([2-9]\d{2})\b',  # 200-999 (3ìë¦¬)
            r'\b([1-9]\d{3})\b',  # 1000-9999 (4ìë¦¬)
        ]
        
        all_prices = []
        
        for pattern in all_price_patterns:
            matches = re.finditer(pattern, all_text, re.IGNORECASE)
            for match in matches:
                price_text = match.group(1).strip()
                
                if price_text not in seen_prices:
                    context_start = max(0, match.start() - 60)
                    context_end = min(len(all_text), match.end() + 60)
                    context = all_text[context_start:context_end].strip()
                    context_lower = context.lower()
                    context = re.sub(r'\s+', ' ', context)[:150]
                    
                    # í‰ê· ê°€ê²© ê°•í™” í•„í„°ë§ 
                    is_average_price = (
                        'with an average room price of' in context_lower or
                        'which stands at' in context_lower or
                        'í‰ê·  ê°ì‹¤ ê°€ê²©ì€' in context_lower or
                        'average room price' in context_lower or
                        'í‰ê·  ê°€ê²©' in context_lower or
                        'í‰ê·  ê°ì‹¤' in context_lower or
                        'ë°©ì½•ì˜ í‰ê· ' in context_lower
                    )
                    
                    # ëª…ë°±í•œ IDë‚˜ ë‚ ì§œë§Œ ì œì™¸
                    is_not_price = (
                        any(year in context for year in ['2024', '2025', '2026']) or
                        (price_text.isdigit() and len(price_text) > 4)  # ê¸´ IDë§Œ ì œì™¸
                    )
                    
                    if not is_average_price and not is_not_price:
                        seen_prices.add(price_text)
                        all_prices.append({
                            'price': f"${price_text}" if not price_text.startswith('$') else price_text,
                            'context': context,
                            'source': 'all_price_search'
                        })
                        
                        # ë” ë§ì´ ìˆ˜ì§‘ (ë‘ ë²ˆì§¸ ê°€ê²©ì„ ì°¾ê¸° ìœ„í•´)
                        if len(all_prices) >= 20:
                            break
            
            if len(all_prices) >= 20:
                break
        
        # ê°€ê²© ë¶„ì„ ì „ì— ë¨¼ì € ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (ë‹¤ìš´ë¡œë“œìš©)
        try:
            import os
            if not os.path.exists('downloads'):
                os.makedirs('downloads')
            
            # CID ì •ë³´ ì¶”ì¶œ
            cid_match = re.search(r'cid=([^&]+)', url)
            cid_value = cid_match.group(1) if cid_match else 'unknown'
            
            # íŒŒì¼ëª… ìƒì„±
            filename = f"page_text_cid_{cid_value}.txt"
            filepath = os.path.join('downloads', filename)
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"URL: {url}\n")
                f.write(f"CID: {cid_value}\n")
                f.write(f"ìŠ¤í¬ë˜í•‘ ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("="*50 + "\n\n")
                f.write(all_text)
            
            print(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ë¨: {filepath}")
            
        except Exception as save_error:
            print(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {save_error}")
        
        # ë‘ ë²ˆì§¸ ê°€ê²©ë§Œ ë°˜í™˜ (ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­)
        if len(all_prices) >= 2:
            prices_found = [all_prices[1]]  # ë‘ ë²ˆì§¸ ê°€ê²©ë§Œ
        elif len(all_prices) >= 1:
            prices_found = [all_prices[0]]  # ì²« ë²ˆì§¸ë¼ë„ ë°˜í™˜
        else:
            prices_found = all_prices  # ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        
        return prices_found
        
    except Exception as e:
        return []

def process_all_cids_sequential(base_url, cid_list):
    """
    ëª¨ë“  CIDë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ê° ê²°ê³¼ë¥¼ ì¦‰ì‹œ ë°˜í™˜
    Generator that yields results immediately as they become available
    """
    original_cid = extract_cid_from_url(base_url)
    total_cids = len(cid_list)
    
    # ì‹œì‘ ì‹ í˜¸
    yield {
        'type': 'start',
        'total_cids': total_cids
    }
    
    # ê° CIDë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
    for i, new_cid in enumerate(cid_list, 1):
        try:
            # URL ìƒì„±
            if original_cid:
                new_url = base_url.replace(f"cid={original_cid}", f"cid={new_cid}")
            else:
                separator = "&" if "?" in base_url else "?"
                new_url = f"{base_url}{separator}cid={new_cid}"
            
            # CID ë¼ë²¨ ìƒì„±
            if i == 1:
                cid_label = f"ì›ë³¸({new_cid})"
            else:
                cid_label = str(new_cid)
            
            # ì§„í–‰ë¥  ì •ë³´
            yield {
                'type': 'progress',
                'step': i,
                'total': total_cids,
                'cid': cid_label
            }
            
            # ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
            start_time = time.time()
            prices = scrape_prices_simple(new_url)
            process_time = time.time() - start_time
            
            # ì¦‰ì‹œ ê²°ê³¼ ë°˜í™˜
            result = {
                'type': 'result',
                'step': i,
                'total': total_cids,
                'cid': cid_label,
                'url': new_url,
                'prices': prices,
                'found_count': len(prices),
                'process_time': round(process_time, 1)
            }
            
            yield result
            
        except Exception as e:
            yield {
                'type': 'error',
                'step': i,
                'total': total_cids,
                'cid': new_cid,
                'error': str(e)
            }
    
    # ì™„ë£Œ ì‹ í˜¸
    yield {
        'type': 'complete',
        'total_results': total_cids
    }

def extract_cid_from_url(url):
    """URLì—ì„œ CID ê°’ ì¶”ì¶œ"""
    match = re.search(r'cid=([^&]+)', url)
    return match.group(1) if match else None

def reorder_url_parameters(url):
    """
    URLì˜ íŒŒë¼ë©”í„°ë¥¼ ì§€ì •ëœ ìˆœì„œë¡œ ì¬ì •ë ¬í•˜ê³  í•„ìš”í•œ íŒŒë¼ë©”í„°ë§Œ ìœ ì§€
    """
    # ì§€ì •ëœ íŒŒë¼ë©”í„° ìˆœì„œ (í•„ìš”í•œ ëª¨ë“  íŒŒë¼ë¯¸í„° í¬í•¨)
    desired_order = [
        'countryId',
        'finalPriceView', 
        'isShowMobileAppPrice',
        'familyMode',
        'adults',
        'children',
        'childs',  # childrenì˜ ë‹¤ë¥¸ í‘œí˜„
        'maxRooms',
        'rooms',
        'checkIn',    # ì²´í¬ì¸ ë‚ ì§œ (camelCase)
        'checkin',    # ì²´í¬ì¸ ë‚ ì§œ (lowercase)
        'checkOut',   # ì²´í¬ì•„ì›ƒ ë‚ ì§œ (camelCase)
        'checkout',   # ì²´í¬ì•„ì›ƒ ë‚ ì§œ (lowercase)
        'isCalendarCallout',
        'childAges',
        'numberOfGuest',
        'missingChildAges',
        'travellerType',
        'showReviewSubmissionEntry',
        'currencyCode',
        'currency',
        'isFreeOccSearch',
        'los',
        'textToSearch',  # ê²€ìƒ‰ í…ìŠ¤íŠ¸ ì¶”ê°€
        'productType',   # ìƒí’ˆ íƒ€ì… ì¶”ê°€
        'searchrequestid',
        'ds',           # ds íŒŒë¼ë¯¸í„° ì¶”ê°€
        'cid'
    ]
    
    try:
        # URL íŒŒì‹±
        parsed_url = urlparse(url)
        query_string = parsed_url.query
        
        # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ íŒŒë¼ë©”í„° ì¶”ì¶œ (ë””ì½”ë”© ì—†ì´)
        params_dict = {}
        
        # ì¿¼ë¦¬ ìŠ¤íŠ¸ë§ì„ &ë¡œ ë¶„ë¦¬í•˜ì—¬ íŒŒë¼ë©”í„° ì¶”ì¶œ
        if query_string:
            param_pairs = query_string.split('&')
            for pair in param_pairs:
                if '=' in pair:
                    key, value = pair.split('=', 1)
                    params_dict[key] = value
        
        # ì²´í¬ì¸ ê´€ë ¨ íŒŒë¼ë¯¸í„° í™•ì¸ (ê°„ì†Œí™”)
        checkin_found = [f"{k}={v}" for k, v in params_dict.items() if 'checkin' in k.lower()]
        if checkin_found:
            print(f"ì²´í¬ì¸ ê´€ë ¨ íŒŒë¼ë¯¸í„° ë°œê²¬: {', '.join(checkin_found)}")
        
        # currency íŒŒë¼ë¯¸í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ KRW ì¶”ê°€
        if 'currency' not in params_dict:
            params_dict['currency'] = 'KRW'
            print("currency íŒŒë¼ë¯¸í„°ê°€ ì—†ì–´ì„œ currency=KRWë¡œ ê¸°ë³¸ê°’ ì¶”ê°€")
        
        # ìƒˆë¡œìš´ íŒŒë¼ë©”í„° ë”•ì…”ë„ˆë¦¬ (ì§€ì •ëœ ìˆœì„œëŒ€ë¡œ)
        reordered_params = {}
        
        # ì§€ì •ëœ ìˆœì„œëŒ€ë¡œ íŒŒë¼ë©”í„° ì¶”ê°€ (ì¡´ì¬í•˜ëŠ” ê²½ìš°ë§Œ)
        for param in desired_order:
            if param in params_dict:
                reordered_params[param] = params_dict[param]
        
        # ìƒˆë¡œìš´ ì¿¼ë¦¬ ìŠ¤íŠ¸ë§ ìƒì„±
        query_parts = []
        for key, value in reordered_params.items():
            query_parts.append(f"{key}={value}")
        new_query = "&".join(query_parts)
        
        # ìƒˆë¡œìš´ URL êµ¬ì„±
        new_url = urlunparse((
            parsed_url.scheme,
            parsed_url.netloc,
            parsed_url.path,
            parsed_url.params,
            new_query,
            parsed_url.fragment
        ))
        
        return new_url
        
    except Exception as e:
        print(f"URL íŒŒë¼ë©”í„° ì¬ì •ë ¬ ì˜¤ë¥˜: {e}")
        return url  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ URL ë°˜í™˜

def replace_cid_and_scrape(base_url, cid_list):
    """ê¸°ì¡´ í•¨ìˆ˜ëª… í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼"""
    return process_all_cids_sequential(base_url, cid_list)